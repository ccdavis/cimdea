searchState.loadedDescShard("parquet", 0, "This crate contains the official Native Rust …\nHigh-level API for reading/writing Arrow RecordBatches and …\nContains Rust mappings for Thrift definition. Refer to …\nBloom filter implementation specific to Parquet, as …\nLow level column reader and writer APIs.\nData types that connect Parquet physical types with their …\nCommon Parquet errors and macros.\nLow level APIs for reading raw parquet data.\nAutomatically generated code for reading parquet thrift …\nContains record-based API for reading Parquet files.\nParquet schema definitions and methods to print and parse …\nCustom thrift definitions\nSchema metadata key used to store serialized Arrow IPC …\nSchema information necessary to decode a parquet file as …\nThe value of this metadata key, if present on …\nA <code>ProjectionMask</code> identifies a set of columns within a …\nCreate a <code>ProjectionMask</code> which selects all columns\nContains reader which reads parquet data into arrow …\nConvert arrow schema to parquet schema\nContains writer which writes arrow data into parquet data.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns true if the leaf column <code>leaf_idx</code> is included by …\nCreate a <code>ProjectionMask</code> which selects only the specified …\nConvert a parquet <code>SchemaDescriptor</code> to <code>FieldLevels</code>\nConvert Parquet schema to Arrow schema including optional …\nConvert parquet schema to arrow schema including optional …\nCreate a <code>ProjectionMask</code> which selects only the specified …\nA predicate operating on <code>RecordBatch</code>\nAn <code>ArrowPredicate</code> created from an <code>FnMut</code>\nA generic builder for constructing sync or async arrow …\nThe cheaply clone-able metadata necessary to construct a …\nOptions that control how metadata is read for a parquet …\nAn <code>Iterator&lt;Item = ArrowResult&lt;RecordBatch&gt;&gt;</code> that yields …\nA synchronous builder used to construct …\nA <code>RowFilter</code> allows pushing down a filter predicate to skip …\nA collection of row groups\n<code>RowSelection</code> allows selecting or skipping a provided …\n<code>RowSelection</code> is a collection of <code>RowSelector</code> used to skip …\nreturns a <code>RowSelection</code> representing rows that are selected …\nBuild a <code>ParquetRecordBatchReader</code>\nBuild a <code>ParquetRecordBatchReader</code>\nReturns a <code>PageIterator</code> for the column chunks with the …\nEvaluate this predicate for the given <code>RecordBatch</code> …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreates a <code>RowSelection</code> from a slice of <code>BooleanArray</code>\nCompute the intersection of two <code>RowSelection</code> For example: …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns an iterator over the <code>RowSelector</code>s for this …\nLoads <code>ArrowReaderMetadata</code> from the provided <code>ChunkReader</code>\nReturns a reference to the <code>ParquetMetaData</code> for this …\nReturns a reference to the <code>ParquetMetaData</code> for this …\nCreate a new <code>ArrowPredicateFn</code>. <code>f</code> will be passed batches …\nCreate a new <code>RowFilter</code> from an array of <code>ArrowPredicate</code>\nCreate a new <code>ArrowReaderOptions</code> with the default settings\nCreate a <code>ParquetRecordBatchReaderBuilder</code> from the provided …\nCreate a <code>ParquetRecordBatchReaderBuilder</code> from the provided …\nGet the number of rows in this collection\nReturns the parquet <code>SchemaDescriptor</code> for this parquet file\nReturns the parquet <code>SchemaDescriptor</code> for this parquet file\nReturns the <code>ProjectionMask</code> that describes the columns …\nReturns the number of selected rows\nThe number of rows\nGiven an offset index, return the byte ranges for all data …\nReturns the arrow <code>SchemaRef</code> for this parquet file\nReturns the projected <code>SchemaRef</code> for reading the parquet …\nReturns the arrow <code>SchemaRef</code> for this parquet file\nSelect <code>row_count</code> rows\nReturns <code>true</code> if this <code>RowSelection</code> selects any rows\nSkip <code>row_count</code> rows\nIf true, skip <code>row_count</code> rows\nSplits off the first <code>row_count</code> from this <code>RowSelection</code>\nCreate a new <code>ParquetRecordBatchReaderBuilder</code>\nCreate a new <code>ParquetRecordBatchReaderBuilder</code>\nCreate a new <code>ParquetRecordBatchReader</code> from the provided …\nCreate a new <code>ParquetRecordBatchReaderBuilder</code> with …\nCreate a new <code>ParquetRecordBatchReaderBuilder</code> with …\nCreate a new <code>ParquetRecordBatchReader</code> from the provided …\nSet the size of <code>RecordBatch</code> to produce. Defaults to 1024 …\nProvide a limit to the number of rows to be read\nProvide an offset to skip over the given number of rows\nSet this true to enable decoding of the PageIndex if …\nOnly read data from the provided column indexes\nProvide a <code>RowFilter</code> to skip decoding rows\nOnly read data from the provided row group indexes\nProvide a <code>RowSelection</code> to filter out rows, and avoid …\nParquet files generated by some writers may contain …\nThe data for a single column chunk, see <code>ArrowColumnWriter</code>\nEncodes <code>ArrowLeafColumn</code> to <code>ArrowColumnChunk</code>\nA leaf column that can be encoded by <code>ArrowColumnWriter</code>\nEncodes <code>RecordBatch</code> to parquet\nArrow-specific configuration settings for writing parquet …\nAdditional <code>KeyValue</code> metadata to be written in addition to …\nCalls <code>SerializedRowGroupWriter::append_column</code> with this …\nReturns the number of bytes written by this instance\nClose and finalize the underlying Parquet writer\nClose this column returning the written <code>ArrowColumnChunk</code>\nComputes the <code>ArrowLeafColumn</code> for a potentially nested …\nClose and finalize the underlying Parquet writer\nFlushes all buffered rows into a new row group\nReturns metadata for any flushed row groups\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the <code>ArrowColumnWriter</code> for a given schema\nReturns the estimated total bytes for this column writer\nReturns the number of rows buffered in the in progress row …\nReturns the estimated length in bytes of the current in …\nReturns a reference to the underlying writer.\nReturns a mutable reference to the underlying writer.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nFlushes any outstanding data and returns the underlying …\nCreates a new <code>ArrowWriterOptions</code> with the default settings.\nTry to create a new Arrow writer\nTry to create a new Arrow writer with <code>ArrowWriterOptions</code>.\nSets the <code>WriterProperties</code> for writing parquet files.\nParquet files generated by the <code>ArrowWriter</code> contain …\nEncodes the provided <code>RecordBatch</code>\nWrite an <code>ArrowLeafColumn</code>\n<strong>Deprecated</strong> Bit-packed encoding.\nA BSON document embedded within a single BINARY column.\nEncoding for floating-point data.\nRepresents a valid brotli compression level.\nColumn order that specifies what method was used to …\nSupported block compression algorithms.\nCommon types (converted types) used by frameworks when …\nA date stored as days since Unix epoch, encoded as the …\nA decimal value. This may be used to annotate binary or …\nDelta encoding for integers, either INT32 or INT64.\nIncremental encoding for byte arrays.\nEncoding for byte arrays to separate the length values and …\nAn enum is converted into a binary field\nEncodings supported by Parquet.\nRepresents a valid gzip compression level.\nAn interval of time.\nA signed 16 bit integer value stored as INT32 physical …\nA signed 32 bit integer value stored as INT32 physical …\nA signed 64 bit integer value stored as INT64 physical …\nA signed 8 bit integer value stored as INT32 physical type.\nA JSON document embedded within a single UTF8 column.\nA list is converted into an optional field containing a …\nLogical types used by version 2.4.0+ of the Parquet format.\nA map is converted as an optional field containing a …\nA key/value pair is converted into a group of two fields.\nField is optional (can be null) and each record has 0 or 1 …\nDefault byte encoding.\n<strong>Deprecated</strong> dictionary encoding.\nAvailable data pages for Parquet file format. Note that …\nField is repeated and can contain 0 or more values.\nField is required (can not be null) and each record has …\nGroup packed run length encoding.\nDictionary encoding.\nRepresentation of field types in schema.\nSigned (either value or legacy byte-wise) comparison.\nSort order for page and column statistics.\nDate and time recorded as microseconds since the Unix …\nDate and time recorded as milliseconds since the Unix …\nThe total number of microseconds since midnight. The value …\nThe total number of milliseconds since midnight. The value …\nColumn uses the order defined by its logical or physical …\nTypes supported by Parquet. These physical types are …\nAn unsigned 16 bit integer value stored as INT32 physical …\nAn unsigned 32 bit integer value stored as INT32 physical …\nAn unsigned 64 bit integer value stored as INT64 physical …\nAn unsigned 8 bit integer value stored as INT32 physical …\nComparison is undefined.\nUndefined column order, means legacy behaviour before …\nUnsigned (depending on physical type either value or …\nA BYTE_ARRAY actually contains UTF8 encoded chars.\nRepresents a valid zstd compression level.\nReturns the compression level.\nReturns the compression level.\nReturns the compression level.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns sort order for a physical/logical type.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns true if this is <code>Self::SIGNED</code>\nReturns sort order associated with this column order.\nAttempts to create a gzip compression level.\nAttempts to create a brotli compression level.\nAttempts to create a zstd compression level from a given …\nA split block Bloom filter. The creation of this structure …\nCheck if an AsBytes value is probably present or …\nReturns the argument unchanged.\nInsert an AsBytes value into the filter\nCalls <code>U::from(self)</code>.\nContains Parquet Page definitions and page reader …\nContains column reader API.\nContains column writer API.\nHelper struct to represent pages with potentially …\nParquet Page definition.\nAn iterator over pages of one specific column in a parquet …\nContains metadata for a page\nAPI for reading pages from a column chunk. This offers a …\nContains page write metrics.\nAPI for writing pages in a column chunk.\nReturns <code>true</code> if the next page can be assumed to contain …\nReturns internal byte buffer reference for this page.\nCloses resources and flushes underlying sink. Page writer …\nReturns underlying page with potentially compressed buffer.\nReturns compressed size in bytes.\nReturns slice of compressed buffer in the page.\nReturns encoding for values in page.\nReturns this page <code>Encoding</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGets the next page in the column chunk associated with …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns true if the page is a dictionary page\nCreates <code>CompressedPage</code> from a page with potentially …\nCreates new spec with default page write metrics.\nThe number of levels within the page if known\nThe number of rows within the page if known\nNumber of values in page.\nReturns number of values in this page.\nReturns page type.\nReturns <code>PageType</code> for this page.\nGets metadata about the next page, returns an error if no …\nSkips reading the next page, returns an error if no column …\nReturns optional <code>Statistics</code>.\nReturns uncompressed size in bytes.\nWrites column chunk metadata into the output stream/sink.\nWrites a page into the output stream/sink. Returns …\nColumn reader for a Parquet type.\nTyped value reader for a particular primitive column.\nReads data for a given column chunk, using the provided …\nReturns the argument unchanged.\nReturns the argument unchanged.\nGets a specific column reader corresponding to column …\nGets a typed column reader for the specific type <code>T</code>, by “…\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates new column reader based on column descriptor and …\nReads a batch of values of at most <code>batch_size</code>, returning a …\nRead up to <code>max_records</code> whole records, returning the number …\nSkips over <code>num_records</code> records, where records are …\nMetadata returned by <code>GenericColumnWriter::close</code>\nColumn writer for a Parquet type.\nTyped column writer for a primitive column.\nOptional bloom filter for this column\nThe total number of bytes written\nClose this <code>ColumnWriter</code>\nFinalizes writes and closes the column writer. Returns …\nOptional column index, for filtering\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGets a specific column writer corresponding to column …\nReturns a reference to a <code>ColumnDescPtr</code>\nReturns total number of bytes written by this column …\nReturns total number of rows written by this column writer …\nGets a typed column writer for the specific type <code>T</code>, by “…\nSimilar to <code>get_typed_column_writer</code> but returns a reference.\nSimilar to <code>get_typed_column_writer</code> but returns a reference.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMetadata for this column chunk\nOptional offset index, identifying page locations\nThe total number of rows written\nWrites batch of values, definition levels and repetition …\nWriter may optionally provide pre-calculated statistics …\nConverts an instance of data type to a slice of bytes as <code>u8</code>…\nRust representation for BYTE_ARRAY and …\nDecimal backed by byte array.\nContains the Parquet physical type information as well as …\nRust representation for Decimal values.\nWrapper type for performance reasons, this represents …\nDecimal backed by <code>i32</code>.\nDecimal backed by <code>i64</code>.\nRust representation for logical type INT96, value is …\nConverts an slice of a data type to a slice of bytes.\nReturns slice of bytes for this data type.\nReturns underlying data as slice of <code>u32</code>.\nReturns slice of data.\nReturns bytes of unscaled value.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreates new decimal value from <code>ByteArray</code>.\nCreates new decimal value from <code>i32</code>.\nCreates new decimal value from <code>i64</code>.\nReturns Parquet physical type.\nReturns size in bytes for Rust representation of the …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nChecks if the underlying buffer is empty.\nGets length of the underlying byte buffer.\nCreates new INT96 type struct with no data set.\nCreates new byte array with no data set.\nReturns decimal precision.\nReturns decimal scale.\nSets data for this INT96 type.\nSet data from another byte buffer.\nReturns <code>ByteArray</code> instance with slice of values for a data.\nReturns slice of bytes for a slice of this data type.\nReturn the internal representation as a mutable slice\nConverts this INT96 into an i64 representing the number of …\nConverts this INT96 into an i64 representing the number of …\nConverts this INT96 to a number of seconds and nanoseconds …\nArrow error. Returned when reading into arrow or writing …\n“End of file” Parquet error. Returned when IO related …\nContains the error value\nAn external error variant\nGeneral Parquet error. Returned when code violates normal …\n“Not yet implemented” Parquet error. Returned when …\nContains the success value\nParquet error enumeration\nA specialized <code>Result</code> for Parquet errors.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe length of the parquet footer in bytes\nContains information about available Parquet metadata.\nPer-page encoding information.\nPage Index of “Column Index Layout to Support Page …\nConfiguration via <code>WriterProperties</code> and <code>ReaderProperties</code>\nFile reader API and methods to access file metadata, row …\nContains implementations of the reader traits FileReader, …\nContains definitions for working with Parquet statistics.\nContains file writer API, and provides methods to write …\nDecodes the footer returning the metadata length in bytes\nDecodes <code>ParquetMetaData</code> from the provided bytes\nLayout of Parquet file +—————————+—–+…\nMetadata for a column chunk.\nBuilder for column chunk metadata.\nBuilder for column index\nMetadata for a Parquet file.\nReference counted pointer for <code>FileMetaData</code>.\nBuilder for offset index\n<code>Index</code> for each row group of each column.\nGlobal Parquet metadata.\n<code>PageLocation</code> for each datapage of each row group of each …\nMetadata for a row group.\nBuilder for row group metadata.\nReference counted pointer for <code>RowGroupMetaData</code>.\nReturns the offset for the bloom filter.\nReturns the offset for the bloom filter.\nBuilds row group metadata.\nBuilds column chunk metadata.\nBuild and get the thrift metadata of column index\nBuild and get the thrift metadata of offset index\nReturns builder for row group metadata.\nReturns builder for column chunk metadata.\nReturns the offset and length in bytes of the column chunk …\nReturns column chunk metadata for <code>i</code>th column.\nDescriptor for this column.\nReference counted clone of descriptor for this column.\nReturns the column index for this file if loaded\nReturns the offset for the column index length.\nReturns the offset for the column index.\nReturns column order for <code>i</code>th column in this file. If …\nColumn (sort) order used for <code>min</code> and <code>max</code> values of each …\nPath (or identifier) of this column.\nType of this column. Must be primitive.\nReturns slice of column chunk metadata.\nTotal size of all compressed column data in this row group.\nReturns the total compressed data size of this column …\nCompression for this column.\nString message for application that wrote this file.\nReturns the offset for the column data.\nReturns the offset for the dictionary page, if any.\nAll encodings used for this column.\nReturns file metadata as reference.\nReturns file offset of this row group in file.\nByte offset in <code>file_path()</code>.\nFile where the column chunk is stored.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nMethod to convert from Thrift.\nMethod to convert from Thrift.\nReturns the offset for the index page.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConverts this <code>RowGroupMetaData</code> into a …\nConverts this <code>ColumnChunkMetaData</code> into a …\nReturns key_value_metadata of this file.\nCreates Parquet metadata from file metadata and a list of …\nCreates new file metadata.\nCreates Parquet metadata from file metadata, a list of row …\nNumber of columns in this row group.\nReturns number of row groups in this file.\nReturns number of rows in the file.\nNumber of rows in this row group.\nTotal number of values in this column chunk.\nReturns offset indexes in this file.\nReturns the offset for the offset index length.\nReturns the offset for the offset index.\nReturns the offset index for this file if loaded\nReturns ordinal of this row group in file\nReturns the offset for the page encoding stats, or <code>None</code> if …\nReturns page indexes in this file.\nReturns row group metadata for <code>i</code>th position. Position …\nReturns slice of row groups in this file.\nReturns Parquet <code>Type</code> that describes schema in this file.\nReturns a reference to schema descriptor.\nReturns reference to a schema descriptor.\nReturns reference counted clone for schema descriptor.\nReturns reference counted clone of schema descriptor.\nSets optional bloom filter length in bytes.\nSets optional bloom filter offset in bytes.\nSets optional column index length in bytes.\nSets optional column index offset in bytes.\nSets column metadata for this row group.\nSets compression.\nSets data page offset in bytes.\nSets optional dictionary page ofset in bytes.\nSets list of encodings for this column chunk.\nSets file offset in bytes.\nSets optional file path for this column chunk.\nSets optional index page offset in bytes.\nSets number of rows in this row group.\nSets number of values.\nSets optional offset index length in bytes.\nSets optional offset index offset in bytes.\nSets ordinal for this row group.\nSets page encoding stats for this column chunk.\nSets the sorting order for columns\nSets statistics for this column chunk.\nSets total size in bytes for this row group.\nSets total compressed size in bytes.\nSets total uncompressed size in bytes.\nReturns the sort ordering of the rows in this RowGroup if …\nReturns statistics that are set for this column chunk, or …\nMethod to convert to Thrift <code>ColumnMetaData</code>\nMethod to convert to Thrift.\nMethod to convert to Thrift.\nTotal byte size of all uncompressed column data in this …\nReturns the total uncompressed data size of this column …\nReturns version of this file.\nPageEncodingStats for a column chunk and data page.\nnumber of pages of this type with this encoding\nencoding of the page\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nthe page type (data/dic/…)\nConverts <code>PageEncodingStats</code> into Thrift definition.\nConverts Thrift definition into <code>PageEncodingStats</code>.\n<code>Index</code> structures holding decoded <code>ColumnIndex</code> information\nSupport for reading <code>Index</code> and <code>PageLocation</code> from parquet …\nTyped statistics for a data page in a column chunk. This …\nSometimes reading page index from parquet file will only …\nStores the <code>PageIndex</code> for each page of a column\nPageIndex Statistics for one data page, as described in …\nIf the min/max elements are ordered, and if so in which …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet boundary_order of this page index.\nThe indexes, one item per page\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturn min/max elements inside ColumnIndex are ordered or …\nThe maximum value, It is None when all values are null\nThe minimum value, It is None when all values are null\nNull values in the page\nReads per-column <code>Index</code> for all columns of a row group by …\nReads per-page <code>PageLocation</code> for all columns of a row group …\nControls the bloom filter to be computed by the writer.\nCompute chunk-level statistics but not page-level\nDefault value for <code>BloomFilterProperties::fpp</code>\nDefault value for <code>BloomFilterProperties::ndv</code>\nDefault value for …\nDefault value for <code>WriterProperties::compression</code>\nDefault value for <code>WriterProperties::created_by</code>\nDefault value for <code>WriterProperties::dictionary_enabled</code>\nDefault value for …\nDefault value for <code>WriterProperties::max_row_group_size</code>\nDefault value for <code>WriterProperties::max_statistics_size</code>\nDefault value for <code>WriterProperties::data_page_size_limit</code>\nDefault value for <code>WriterProperties::statistics_enabled</code>\nDefault values for …\nDefault value for <code>WriterProperties::writer_version</code>\nDefault value for <code>WriterProperties::write_batch_size</code>\nControls the level of statistics to be computed by the …\nCompute no statistics\nCompute page-level and chunk-level statistics\nConfiguration settings for reading parquet files.\nBuilder for parquet file reader configuration. See example …\nReference counted reader properties.\nConfiguration settings for writing parquet files.\nBuilder for parquet file writer configuration. See example …\nReference counted writer properties.\nParquet writer version.\nReturns writer version as <code>i32</code>.\nReturns the <code>BloomFilterProperties</code> for the given column\nFinalizes the configuration and returns immutable writer …\nFinalizes the configuration and returns immutable reader …\nReturns builder for reader properties with default values.\nReturns builder for writer properties with default values.\nReturns the maximum length of truncated min/max values in …\nReturns compression codec for a column.\nReturns <code>created_by</code> string.\nReturns the maximum page row count\nReturns data page size limit.\nReturns data page size limit.\nReturns encoding for a data page, when dictionary encoding …\nReturns <code>true</code> if dictionary encoding is enabled for a …\nReturns encoding for dictionary page, when dictionary …\nReturns dictionary page size limit.\nReturns dictionary page size limit.\nReturns encoding for a column, if set. In case when …\nFalse positive probability, should be always between 0 and …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns <code>key_value_metadata</code> KeyValue pairs.\nReturns maximum number of rows in a row group.\nReturns max size for statistics. Only applicable if …\nNumber of distinct values, should be non-negative to be …\nCreate a new <code>WriterProperties</code> with the default settings\nEnable/disable backward compatible LZ4.\nSets whether bloom filter is enabled for any column. If …\nSets bloom filter false positive probability (fpp) for any …\nSets number of distinct values (ndv) for bloom filter for …\nSets whether a bloom filter should be created for a …\nSets the false positive probability for bloom filter for a …\nSets the number of distinct values for bloom filter for a …\nSets compression codec for a column. Takes precedence over …\nSets flag to enable/disable dictionary encoding for a …\nSets encoding for a column. Takes precedence over globally …\nSets the max length of min/max value fields in the column …\nSets max size for statistics for a column. Takes …\nSets flag to enable/disable statistics for a column. Takes …\nSets compression codec for any column.\nSets “created by” property.\nSets best effort maximum number of rows in a data page.\nSets best effort maximum size of a data page in bytes.\nSets best effort maximum size of a data page in bytes.\nSets flag to enable/disable dictionary encoding for any …\nSets best effort maximum dictionary page size, in bytes.\nSets best effort maximum dictionary page size, in bytes.\nSets encoding for any column.\nSets “key_value_metadata” property.\nSets maximum number of rows in a row group.\nSets max statistics size for any column. Applicable only …\nEnable/disable reading bloom filter\nSets sorting order of rows in the row group if any\nSets flag to enable/disable statistics for any column.\nSets the max length of min/max value fields in statistics. …\nSets write batch size.\nSets writer version.\nReturns sorting columns.\nReturns <code>true</code> if statistics are enabled for a column.\nReturns the maximum length of truncated min/max values in …\nReturns configured batch size for writes.\nReturns configured writer version.\nThe ChunkReader trait generates readers of chunks of a …\nImplementation of page iterator for parquet file.\nParquet file reader API. With this, user can get metadata …\nLength should return the total number of bytes in the …\nParquet row group reader API. With this, user can get …\nReturns the argument unchanged.\nGet a range as bytes\nGet bloom filter for the <code>i</code>th column chunk, if present and …\nGet page reader for the <code>i</code>th column chunk.\nGet value reader for the <code>i</code>th column chunk.\nGet a <code>Read</code> starting at the provided file offset\nGet the <code>i</code>th row group reader. Note this doesn’t do bound …\nGet an iterator over the row in this file, see <code>RowIter</code> for …\nGet an iterator over the row in this file, see <code>RowIter</code> for …\nCalls <code>U::from(self)</code>.\nReturns the amount of bytes of the inner source.\nGet metadata information about this file.\nGet metadata information about this row group.\nCreates a page iterator for all row groups in file.\nGet the total number of column chunks in this row group.\nGet the total number of row groups for this file.\nCreate page iterator from parquet file reader with only …\nA predicate for filtering row groups, invoked with the …\nA collection of options for reading a Parquet file.\nA builder for <code>ReadOptions</code>. For the predicates that are …\nA serialized implementation for Parquet <code>FileReader</code>.\nA serialized implementation for Parquet <code>PageReader</code>.\nA serialized implementation for Parquet <code>RowGroupReader</code>.\nSeal the builder and return the read options\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nget bloom filter for the <code>i</code>th column\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates file reader from a Parquet file. Returns error if …\nCreates new row group reader from a file, row group …\nCreates a new serialized page reader from a chunk reader …\nNew builder\nCreates file reader from a Parquet file with read options. …\nCreates a new serialized page with custom options.\nEnable reading the page index structures described in “…\nAdd a predicate on row group metadata to the reading …\nAdd a range predicate on filtering row groups if their …\nSet the <code>ReaderProperties</code> configuration.\nStatistics for a column chunk and data page.\nTyped implementation for <code>Statistics</code>.\nStatistics for a particular <code>ParquetValueType</code>\nReturns optional value of number of distinct values …\nReturns optional value of number of distinct values …\nReturns the argument unchanged.\nReturns the argument unchanged.\nConverts Thrift definition into <code>Statistics</code>.\nReturns <code>true</code> if min value and max value are set. Normally …\nWhether or not min and max values are set. Normally both …\nReturns <code>true</code> if statistics collected any null values, <code>false</code>…\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nOld versions of parquet stored statistics in <code>min</code> and <code>max</code> …\nOld versions of parquet stored statistics in <code>min</code> and <code>max</code> …\nReturns <code>true</code> if statistics have old <code>min</code> and <code>max</code> fields set.\nReturns max value of the statistics.\nReturns slice of bytes that represent max value. Panics if …\nReturns max value as bytes of the statistics.\nReturns <code>true</code> if the max value is set, and is an exact max …\nWhether or not max value is set, and is an exact value.\nReturns min value of the statistics.\nReturns slice of bytes that represent min value. Panics if …\nReturns min value as bytes of the statistics.\nReturns <code>true</code> if the min value is set, and is an exact min …\nWhether or not min value is set, and is an exact value.\nCreates new typed statistics.\nReturns number of null values for the column. Note that …\nReturns null count.\nReturns physical type associated with statistics.\nSet whether to write the deprecated <code>min</code> and <code>max</code> fields for …\nSet whether the stored <code>max</code> field represents the exact …\nSet whether the stored <code>min</code> field represents the exact …\nCallback invoked on closing a column chunk\nCallback invoked on closing a row group, arguments are:\nA wrapper around a <code>ColumnWriter</code> that invokes a callback on …\nParquet file writer API. Provides methods to write row …\nA serialized implementation for Parquet <code>PageWriter</code>. Writes …\nParquet row group writer API. Provides methods to access …\nA wrapper around a <code>Write</code> that keeps track of the number of …\nAppend an encoded column chunk from another source without …\nReturns the number of bytes written to this instance\nReturns the number of bytes written to this instance\nCloses and finalises file writer, returning the file …\nCloses this row group writer and returns row group …\nClose this <code>SerializedColumnWriter</code>\nClose and finalize the underlying Parquet writer\nReturns metadata for any flushed row groups\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns a reference to the underlying writer.\nReturns a reference to the underlying writer.\nReturns a mutable reference to the underlying writer.\nReturns a mutable reference to the underlying writer.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the underlying writer.\nWrites the file footer and returns the underlying writer.\nCreate a new <code>TrackedWrite</code> from a <code>Write</code>\nCreates new file writer.\nCreates a new <code>SerializedRowGroupWriter</code> with:\nCreate a new <code>SerializedColumnWriter</code> from a <code>ColumnWriter</code> …\nCreates new page writer.\nReturns the next column writer, if available; otherwise …\nCreates new row group from this file writer. In case of IO …\nReturns a reference to the writer properties\nReturns a reference to schema descriptor.\nReturns a reference to a typed <code>ColumnWriterImpl</code>\nReturns a reference to an untyped <code>ColumnWriter</code>\nBit packed encoding.  This can only be used if the data …\nAn embedded BSON document\nEncoding for floating-point data. K byte-streams are …\nBloom filter header is stored at beginning of Bloom filter …\nEnum to annotate whether lists of min/max elements inside …\nEmbedded BSON logical type annotation\nDescription for ColumnIndex. Each <code>&lt;array-field&gt;</code>[i] refers …\nDescription for column metadata\nSupported compression algorithms.\nDEPRECATED: Common types used by frameworks(e.g. hive, …\nA Date\nA decimal value.\nDelta encoding for integers. This can be used for int …\nIncremental-encoded byte array. Prefix lengths are encoded …\nEncoding for byte arrays to separate the length values and …\nData page header\nNew page format allowing reading levels without …\nDecimal logical type annotation\nThe dictionary page must be placed at the first position …\nan enum is converted into a binary field\nEncodings supported by Parquet.  Not all encodings are …\nRepresentation of Schemas\nCrypto metadata for files with encrypted footer *\nDescription for file metadata\nAn interval of time\nA signed integer value.\nInteger logical type annotation\nAn embedded JSON document\nEmbedded JSON logical type annotation\nWrapper struct to store key values\na list is converted into an optional field containing a …\na map is converted as an optional field containing a …\na key/value pair is converted into a group of two fields\nTime units for logical types\nLogical type to annotate a column that is always null.\nThe field is optional (can be null) and each record has 0 …\nDefault encoding. BOOLEAN - 1 bit per value. 0 is false; 1 …\nDeprecated: Dictionary encoding. The values in the …\nstatistics of a given page type and encoding\nThe field is repeated and can contain 0 or more values\nThis field is required (can not be null) and each record …\nGroup packed run length encoding. Usable for …\nDictionary encoding: the ids are encoded using the RLE …\nRepresents a element inside a schema definition.\nWrapper struct to specify sort order\nBlock-based algorithm type annotation. *\nStatistics per row group and per page All fields are …\nEmpty structs to use as logical type annotations\nA date/time combination\nA date/time combination\nA time.\nA time\nTime logical type annotation\nTimestamp logical type annotation\nTypes supported by Parquet.  These types are intended to …\nEmpty struct to signal the order defined by the physical …\nAn unsigned integer value.\na BYTE_ARRAY actually contains UTF8 encoded chars\nThe compression used in the Bloom filter.\nHash strategy type annotation. xxHash is an extremely fast …\nUnique file identifier part of AAD suffix *\nUnique file identifier part of AAD suffix *\nAAD prefix *\nAAD prefix *\nThe algorithm for setting bits. *\nSize of Bloom filter data including the serialized header, …\nByte offset from beginning of file to Bloom filter data. *\nStores whether both min_values and max_values are ordered …\nCompression codec *\nThe column index (in this row group) *\nSize of ColumnChunk’s ColumnIndex, in bytes *\nFile offset of ColumnChunk’s ColumnIndex *\nSort order used for the min_value and max_value fields in …\nMetadata for each column chunk in this row group. This …\nCompressed (and potentially encrypted) page size in bytes, …\nSize of the page, including header. Sum of …\nThe compression used in the Bloom filter *\nDEPRECATED: When the schema is the result of a conversion …\nnumber of pages of this type with this encoding *\nThe 32-bit CRC checksum for the page, to be be calculated …\nString for application that wrote this file.  This should …\nCrypto metadata of encrypted columns *\nByte offset from beginning of file to first data page *\nEncoding used for definition levels *\nlength of the definition levels\nIf true, indicates this column is sorted in descending …\nByte offset from the beginning of file to first (only) …\ncount of distinct values occurring\nEncoding used for this data page *\nEncoding using this dictionary page *\nEncoding used for data in this page *\nencoding of the page *\nSet of all encodings used for pages in this column chunk. …\nSet of all encodings used for this column. The purpose is …\nEncrypted column metadata for this chunk *\nEncryption algorithm. This field is set only in encrypted …\nEncryption algorithm. This field is only used for files …\nWhen the original schema supports field ids, this will …\nByte offset in file_path to the ColumnMetaData *\nByte offset from beginning of file to first page (data or …\nFile where column data is stored.  If not set, assumed to …\nIndex within the RowGroup of the first row of the page; …\nRetrieval metadata of key used for signing the footer. …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe hash function used for Bloom filter. *\nByte offset from beginning of file to root index page *\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nwhether the values are compressed. Which means the section …\nIf true, max_value is the actual maximum value for a column\nIf true, min_value is the actual minimum value for a column\nIf true, the entries in the dictionary are sorted in …\nRetrieval metadata of column encryption key *\nRetrieval metadata of key used for encryption of footer, …\nOptional key/value metadata *\nOptional key/value metadata *\nThe logical type of this SchemaElement\nDEPRECATED: min and max value of the column. Use min_value …\nLower and upper bound values for the column, determined by …\nColumn metadata for this chunk. This is the same content …\nTwo lists containing lower and upper bounds for the values …\nName of the field in the schema\ncount of null value in the column\nA list containing the number of null values for each page *\nA list of Boolean values to determine the validity of the …\nIf true, nulls will come before non-null values, otherwise,\nThe size of bitset in bytes *\nNested fields.  Since thrift does not support nested …\nNumber of NULL values, in this data page. Number of …\nNumber of rows in this data page. which means pages change …\nNumber of rows in this row group *\nNumber of rows in this file *\nNumber of values, including NULLs, in this data page. *\nNumber of values in the dictionary *\nNumber of values, including NULLs, in this data page. *\nNumber of values in this column *\nOffset of the page in the file *\nSize of ColumnChunk’s OffsetIndex, in bytes *\nFile offset of ColumnChunk’s OffsetIndex *\nRow group ordinal in the file *\nPageLocations, ordered by increasing PageLocation.offset. …\nthe page type (data/dic/…) *\nPath in schema *\nColumn path in schema *\nEncoding used for repetition levels *\nlength of the repetition levels\nrepetition of the field. The root of the schema does not …\nRow groups in this file *\nDEPRECATED: Used when this column contains decimal data. …\nParquet schema for this file.  This schema contains …\nIf set, specifies a sort ordering of the rows in this …\nOptional statistics for the data in this page*\noptional statistics for the data in this page *\noptional statistics for this column chunk\nIn files encrypted with AAD prefix without storing it, …\nIn files encrypted with AAD prefix without storing it, …\nTotal byte size of all the uncompressed column data in …\ntotal byte size of all compressed, and potentially …\nTotal byte size of all compressed (and potentially …\ntotal byte size of all uncompressed pages in this column …\nData type for this field. Not set if the current element …\nthe type of the page: indicates which of the *_header …\nType of this column *\nIf type is FIXED_LEN_BYTE_ARRAY, this is the byte length …\nUncompressed page size in bytes (not including this …\nVersion of this file *\nBoolean value (<code>true</code>, <code>false</code>).\nSigned integer INT_8.\nGeneral binary value.\nDate without a time of day, stores the number of days from …\nDecimal value.\nIEEE 64-bit floating point value.\nAPI to represent a single field in a <code>Row</code>.\nIEEE 32-bit floating point value.\nIEEE 16-bit floating point value.\nStruct, child elements are tuples of field-value pairs.\nSigned integer INT_32.\n<code>List</code> represents a list which contains an array of elements.\nTrait for type-safe access of an index for a <code>List</code>. Note …\nList of elements.\nSigned integer INT_64.\n<code>Map</code> represents a map which contains a list of key-&gt;value …\nTrait for type-safe access of an index for a <code>Map</code>\nList of key-value pairs.\nNull value.\nread up to <code>max_records</code> records from <code>row_group_reader</code> into …\n<code>write_to_row_group</code> writes from <code>self</code> into <code>row_group_writer</code> …\n<code>Row</code> represents a nested Parquet record.\nTrait for type-safe convenient access to fields within a …\n<code>RowColumnIter</code> represents an iterator over column names and …\nTrait for formatting fields within a Row.\nSigned integer INT_16.\nUTF-8 encoded character string.\nMicroseconds from the Unix epoch, 1 January 1970.\nMilliseconds from the Unix epoch, 1 January 1970.\nConverts Parquet BOOLEAN type with logical type into <code>bool</code> …\nConverts Parquet BYTE_ARRAY type with converted type into …\nConverts Parquet DOUBLE type with converted type into <code>f64</code> …\nConverts Parquet FLOAT type with logical type into <code>f32</code> …\nConverts Parquet INT32 type with converted type into <code>i32</code> …\nConverts Parquet INT64 type with converted type into <code>i64</code> …\nConverts Parquet INT96 (nanosecond timestamps) type and …\nGet Display reference for a given field.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet an iterator to go through all columns in the row.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nDetermines if this Row represents a primitive value.\nGet the number of fields in this row.\nGet the number of fields in this row\nGet the number of fields in this row\nContains implementation of record assembly and converting …\nGenerated schema\nReader tree for record assembly\nInternal iterator of <code>Row</code>s for a reader.\nAccess parquet data as an iterator of <code>Row</code>\nTree builder for <code>Reader</code> enum. Serves as a container of …\nCreates iterator of <code>Row</code>s directly from schema descriptor …\nCreates new root reader for provided schema and row group.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreates iterator of <code>Row</code>s for all row groups in a file.\nCreates a iterator of <code>Row</code>s from a <code>FileReader</code> using the …\nCreates iterator of <code>Row</code>s for a specific row group.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates new tree builder with default parameters.\nTries to create a iterator of <code>Row</code>s using projections. …\nSets batch size for this tree builder.\nSets batch size for this row iter.\nParquet schema parser. Provides methods to parse and …\nParquet schema printer. Provides methods to print Parquet …\nContains structs and methods to build Parquet schema and …\nParses message type as string into a Parquet <code>Type</code> which, …\nPrints file metadata <code>FileMetaData</code> information.\nPrints Parquet metadata <code>ParquetMetaData</code> information.\nPrints Parquet <code>Type</code> information.\nBasic type info. This contains information such as the …\nType alias for <code>Arc&lt;ColumnDescriptor&gt;</code>.\nA descriptor for leaf-level primitive columns. This …\nRepresents a path in a nested schema\nA builder for group types. All attributes are optional …\nA builder for primitive types. All attributes are optional …\nType alias for <code>Arc&lt;SchemaDescriptor&gt;</code>.\nA schema descriptor. This encapsulates the top-level …\nRepresentation of a Parquet type. Used to describe …\nType alias for <code>Arc&lt;Type&gt;</code>.\nAppends more components to end of column path.\nCreates a new <code>PrimitiveType</code> instance from the collected …\nCreates a new <code>GroupType</code> instance from the gathered …\nChecks if <code>sub_type</code> schema is part of current schema. This …\nReturns <code>ColumnDescriptor</code> for a field position.\nReturns slice of <code>ColumnDescriptor</code>.\nReturns <code>ConvertedType</code> value for the type.\nReturns <code>ConvertedType</code> for this column.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nMethod to convert from Thrift.\nReturns <code>BasicTypeInfo</code> information about the type.\nReturns column root <code>Type</code> for a leaf position.\nReturns the index of the root column for a field position\nReturns column root <code>Type</code> pointer for a leaf position.\nGets the fields from this group type. Note that this will …\nGets physical type of this primitive type. Note that this …\nGets precision of this primitive type. Note that this will …\nGets scale of this primitive type. Note that this will …\nCreates group type builder with provided column name.\nReturns <code>true</code> if id is set, <code>false</code> otherwise.\nReturns <code>true</code> if type has repetition field set, <code>false</code> …\nReturns id value for the type.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns <code>true</code> if this type is a group type, <code>false</code> otherwise.\nReturns <code>true</code> if this type is repeated or optional. If this …\nReturns <code>true</code> if this type is a primitive type, <code>false</code> …\nReturns <code>true</code> if this type is the top-level schema type …\nReturns <code>LogicalType</code> value for the type.\nReturns <code>LogicalType</code> for this column.\nReturns maximum definition level for this column.\nReturns maximum repetition level for this column.\nReturns this type’s field name.\nReturns field name.\nReturns column name.\nReturns schema name.\nCreates new primitive type builder with provided field …\nCreates new group type builder with provided field name.\nCreates new column path from vector of field names.\nCreates new descriptor for leaf-level column.\nCreates new schema descriptor from Parquet schema.\nReturns number of leaf-level columns.\nReturns <code>ColumnPath</code> for this column.\nReturns physical type for this column. Note that it will …\nCreates primitive type builder with provided field name …\nReturns <code>Repetition</code> value for the type.\nReturns schema as <code>Type</code>.\nReturns self type <code>Type</code> for this leaf column.\nReturns self type <code>TypePtr</code>  for this leaf column.\nReturns the sort order for this column\nReturns string representation of this column path.\nMethod to convert to Thrift.\nReturns type length for this column. Note that it will …\nReturns type precision for this column. Note that it will …\nReturns type scale for this column. Note that it will …\nSets <code>ConvertedType</code> for this field and returns itself.\nSets <code>ConvertedType</code> for this field and returns itself.\nSets a list of fields that should be child nodes of this …\nSets optional field id and returns itself.\nSets optional field id and returns itself.\nSets type length and returns itself. This is only applied …\nSets <code>LogicalType</code> for this field and returns itself. If …\nSets <code>LogicalType</code> for this field and returns itself.\nSets precision for Parquet DECIMAL physical type and …\nSets <code>Repetition</code> for this field and returns itself.\nSets <code>Repetition</code> for this field and returns itself.\nSets scale for Parquet DECIMAL physical type and returns …\nA utility trait to help user to traverse against parquet …\nA utility method which detects input type and calls …\nDefault implementation when visiting a list.\nCalled by <code>visit_list</code>.\nCalled when a map type hit.\nCalled when a primitive type hit.\nCalled when a struct type hit.\nReads and writes the struct to Thrift protocols.")